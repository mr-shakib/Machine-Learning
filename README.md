# 🚀 AI & Generative Intelligence Learning Journey

A structured, goal-driven roadmap documenting my hands-on progress in Artificial Intelligence — from classical Machine Learning to advanced Generative and Agentic AI systems.

---

## 🎯 Objective

To master the modern AI ecosystem — from Machine Learning and NLP to Generative, Multimodal, and Agentic AI — through structured, project-based learning and practical experimentation.

---

## 📊 Overall Progress

| Stage | Progress | Status |
|:------|:----------:|:-------|
| 🧩 Pre-requisites (Python + Statistics) | ██████████ 100% | ✅ Completed |
| 🧠 Core NLP + ML/DL | ████░░░░░░ 40% | ⚙️ In Progress |
| ⚙️ Generative AI Foundations (LLMs) | ██░░░░░░░░ 20% | 🚧 Active |
| 🧰 Frameworks (LangChain, LlamaIndex, Hugging Face) | ████████░░ 80% | ✅ Completed LangChain + Gemini API |
| 🧠 Fine-Tuning (PEFT + Custom Models) | ░░░░░░░░░░ 0% | ⏳ Upcoming |
| 🔍 Retrieval-Augmented Generation (RAG) | ░░░░░░░░░░ 0% | ⏳ Upcoming |
| 🧩 Multimodal AI | ░░░░░░░░░░ 0% | ⏳ Upcoming |
| 🤖 Agentic AI | ░░░░░░░░░░ 0% | ⏳ Upcoming |

> **Overall Completion:** ![Progress](https://progress-bar.dev/35/?title=Learning%20Journey&width=300&color=3B82F6)

---

## 🔹 Stage-by-Stage Breakdown

### ✅ **1. Pre-requisites (Solid Foundation)**
- [x] Python — NumPy, Pandas, Matplotlib, scikit-learn, OOP, APIs  
- [x] Statistics — probability, distributions, hypothesis testing, correlation, regression, matrix operations  
> 🎯 *Goal:* Build a strong analytical foundation to transition into model design.

---

### 🧠 **2. Core NLP + ML/DL** *(40% Complete)*  
- [x] Text preprocessing, tokenization, TF-IDF  
- [x] Word embeddings (Word2Vec, GloVe)  
- [x] Classical NLP models — Naive Bayes, SVM, Logistic Regression  
- [ ] Deep Learning for NLP — RNN → LSTM → GRU  
- [ ] Attention Mechanism & Transformers  
- [ ] Understanding BERT & GPT architecture basics  

📚 **Resources:**  
- *Natural Language Processing with Python (NLTK Book)*  
- *DeepLearning.AI NLP Specialization (Coursera)*  

---

### ⚙️ **3. Generative AI Foundations (LLMs)** *(20% Complete)*  
- [x] Prompt Engineering & Context Optimization  
- [ ] Tokenization, Embeddings, Self-Attention  
- [ ] Training vs Inference (conceptual clarity)  
- [ ] Study of GPT, LLaMA, Mistral, Gemini, Claude  

💡 **Mini Projects (Planned):**
- [ ] Document Q&A Bot (LangChain + LlamaIndex)  
- [ ] Custom Dataset Chatbot (Hugging Face + RAG)

---

### 🧰 **4. Frameworks (LangChain, LlamaIndex, Hugging Face)**  
- [x] LangChain with Gemini API — *Completed* 🎉  
  - Integrated Gemini API with LangChain  
  - Built LLMChain + PromptTemplate + Streamlit UI  
  - Implemented prompt-based response generation  
- [ ] LlamaIndex — for knowledge retrieval & RAG  
- [ ] Hugging Face — model hosting and fine-tuning integration  

> 🧩 *Goal:* Master frameworks that streamline LLM development and deployment.

---

### 🧠 **5. Fine-Tuning (Advanced LLM Skills)**  
- [ ] Learn PEFT techniques — LoRA, QLoRA, Prefix-Tuning, Adapter-Tuning  
- [ ] Fine-tune small LLMs using Hugging Face + PEFT  
- [ ] Train domain-specific chatbot models  

---

### 🔍 **6. Retrieval-Augmented Generation (RAG)**  
- [ ] Understand embeddings & vector databases — FAISS, Pinecone, Chroma  
- [ ] Implement chunking, indexing, and retrieval  
- [ ] Build context-aware chatbots (LangChain / LlamaIndex)  

---

### 🧩 **7. Multimodal AI**  
- [ ] Explore text–vision models — CLIP, BLIP, LLaVA  
- [ ] Integrate speech & text — Whisper, SpeechT5  
- [ ] Understand multimodal fusion techniques  

> 🌐 *Goal:* Learn how language, vision, and speech models merge for richer AI experiences.

---

### 🤖 **8. Agentic AI (Autonomous Systems)**  
- [ ] Study agent frameworks — AutoGPT, CrewAI, LangGraph  
- [ ] Learn tools & function calling  
- [ ] Implement reasoning + planning systems  
- [ ] Experiment with multi-agent collaboration  

> 🚀 *Goal:* Build AI systems that can reason, plan, and act autonomously.

---

## 🗓️ **Learning Timeline (Approx. 6-Month Plan)**

| Month | Focus Area | Outcome |
|:------|:------------|:--------|
| 1 | Python + Statistics | Core Foundation ✅ |
| 2–3 | NLP (ML + DL) | Classical → Transformer NLP |
| 4 | Generative AI + Frameworks | LangChain + Gemini API ✅ |
| 5 | Fine-Tuning & RAG | Custom model specialization |
| 6 | Multimodal + Agentic AI | Advanced AI integration |

---

## 🧠 Specialized Skills in Progress

| Category | Focus |
|:----------|:------|
| **ML/DL** | Model creation, supervised & unsupervised learning |
| **NLP** | Transformers, BERT/GPT, RNNs & variants |
| **Generative AI** | Prompt engineering, LLM fine-tuning, LangChain, LlamaIndex |
| **Frameworks** | LangChain, Hugging Face, LlamaIndex integration |
| **RAG Systems** | Vector retrieval, contextual pipelines |
| **Multimodal & Agentic AI** | Cross-modal reasoning, function calling, memory, planning |

---

## 🧱 Repository Structure




├── 📁 1-prerequisites/            # Python, Statistics, Math for ML

├── 📁 2-classical-nlp/            # Tokenization, TF-IDF, Word2Vec

├── 📁 3-deep-learning-nlp/        # RNN, LSTM, GRU, Transformers

├── 📁 4-generative-ai/            # LLMs, Prompt Engineering, GPT/BERT experiments

├── 📁 5-frameworks/               # LangChain, LlamaIndex, Gemini API ✅ (completed)

├── 📁 6-fine-tuning/              # LoRA, PEFT, Instruction-tuning

├── 📁 7-rag-systems/              # VectorDBs (FAISS/Pinecone), RAG pipelines

├── 📁 8-multimodal/               # CLIP, Gemini, Speech Models

├── 📁 9-agentic-ai/               # AI Agents, Tools, Memory, Autonomy

└── 📁 projects/                   # End-to-End AI Projects



---

## Methodology

- Project-first approach  
- Weekly progress commits  
- Research inspired learning  
- Explain concepts in notes & notebooks  
- Build real, scalable GenAI systems  

---


---

## 🏁 Vision

To design, train, and deploy **intelligent, context-aware AI systems** capable of reasoning, retrieving, and adapting — demonstrating practical mastery of modern AI frameworks and concepts.

---

**Status:** 🟢 Actively Learning  
**Latest Update:** Completed *LangChain + Gemini API Integration* (October 2025)  
**Maintained by:** [Shakib Howlader (Nacht)](https://github.com/mr-shakib)
